GNN-RAG³ 四阶段训练流程总结

一、整体流程
- 顶层入口：`train_gnn_rag.py` 实现四阶段管线：`warmup` → `joint1` → `pcst_distill` → `joint2`。
- 每个阶段通过命令行调用 `python -m gnn.main ReaRev ...` 执行训练/评估，核心训练逻辑在 `gnn/train_model.py::Trainer_KBQA`。
- 阶段结束后，最终评估通过 `gnn.main` 的 `--is_eval` 生成 `*_test.info`，并在 `gnn/outputs/gnn_rag3_<dataset>/final_results.json` 写入聚合指标。

二、阶段配置与传参（train_gnn_rag.py）
- 通用参数构造（`get_common_args`）：
  - 模型固定为 `ReaRev`（作为第一个位置参数）。
  - `--name <dataset>`、`--data_folder gnn/data/<dataset>`、`--checkpoint_dir gnn/outputs/gnn_rag3_<dataset>`。
  - 语言模型：按 `config.language_model` 注入 `--lm`、`--lm_frozen`、`--lm_dropout`。
  - 模型结构：按 `config.model_params` 注入 `--entity_dim`、`--num_iter`、`--num_ins`、`--num_gnn`。
  - 多卡：当 `multi_gpu.enabled=True` 时添加 `--use_multi_gpu` 与 `--gpu_ids`（逗号分隔）。
- RAG³ 专属参数（`get_rag3_args`，非 warmup 阶段才加入）：
  - APPR：`--use_appr`、`--appr_alpha`（默认 0.85）、`--cand_n`（默认 1200）。
  - DDE：`--use_dde`、`--hop_dim`（默认 16）、`--dir_dim`（默认 8）。
  - PCST：`--use_pcst`、`--pcst_lambda cost,conn,sparse`（默认 `0.1,0.1,0.05`）。
  - 中层重启：`--mid_restart`。
- 性能优化参数（`get_opt_args`，所有阶段都传）：
  - `--use_optimization True`、`--enable_sync_optimization`、`--enable_adaptive_subgraph`、`--enable_memory_monitoring`、`--min_candidates`、`--max_candidates`。
- 阶段级训练参数（`run_stage`）：
  - `--experiment_name gnn_rag3_<dataset>-<stage>`，确保产出 `*_best.pt` 别名。
  - `--num_epoch`：若未指定，取 `max_steps // 100`；
  - `--lr`、`--batch_size`、`--eval_every`：当 `eval_every_raw >= 100` 时，传入值为 `eval_every_raw // 100`（将“步频”粗化到“轮频”）。
  - 断点承接：`--load_experiment` 会解析上一阶段 `*_best.pt` 或退化别名（`-f1.ckpt`、`-h1.ckpt`、`-final.ckpt`）。
- 默认阶段配置（可被用户 `config.stages` 覆盖）：
  - warmup：`max_steps=5000`、`lr=1e-3`、`batch_size=32`、`eval_every=500`（传给 `gnn.main` 为 5）。备注：`freeze_gnn`/`train_hybrid_only` 等键仅在配置中记录，不会传入 `gnn.main`。
  - joint1：`max_steps=20000`、`lr=5e-4`、`batch_size=16`、`eval_every=1000`（传为 10）、承接 `warmup_best.pt`。
  - pcst_distill：`max_steps=10000`、`lr=1e-4`、`batch_size=16`、`eval_every=1000`（传为 10）、承接 `joint1_best.pt`。
  - joint2：`max_steps=20000`、`lr=2e-4`、`batch_size=16`、`eval_every=1000`（传为 10）、承接 `pcst_distill_best.pt`。

三、gnn.main 参数解析与运行（gnn/main.py, gnn/parsing.py）
- 解析器 `add_parse_args` 定义模型子解析器，当前使用 `ReaRev`：
  - 训练超参：`--num_epoch`（默认 100）、`--eval_every`（默认 2）、`--batch_size`（默认 20）、`--lr`（默认 5e-4）、`--gradient_clip`（默认 1.0）、`--warmup_epoch`（默认 0）、`--seed`（默认 19960626）、`--fact_drop`（默认 0）。
  - 结构与维度：`--entity_dim`（默认 50）、`--kg_dim`（默认 100）、`--word_dim`（默认 300）、`--lm_dropout`（默认 0.3）、`--linear_dropout`（默认 0.2）。
  - 模型结构（ReaRev）：`--num_iter`（默认 2）、`--num_ins`（默认 3）、`--num_gnn`（默认 3）、`--loss_type`（默认 `kl`）、`--norm_rel`、`--pos_emb` 等。
  - RAG³：`--use_appr`/`--appr_alpha`/`--cand_n`、`--use_dde`/`--hop_dim`/`--dir_dim`、`--use_pcst`/`--pcst_lambda`、`--mid_restart`。
  - 性能优化：`--use_optimization`、`--enable_sync_optimization`、`--enable_adaptive_subgraph`、`--enable_memory_monitoring`、`--min_candidates`、`--max_candidates`。
  - I/O：`--checkpoint_dir`（默认 `checkpoint/pretrain/`；被管线覆盖为 `gnn/outputs/gnn_rag3_<dataset>`）、`--experiment_name`、`--load_experiment`、`--is_eval`。
  - 多卡：`--use_multi_gpu`、`--gpu_ids "0,1"`。
- 运行：
  - 设置 `use_cuda`、解析 `gpu_ids` 列表、可选限制 GPU 内存（`maybe_cap_gpu_memory`）、设定随机种子。
  - 若未显式提供 `--experiment_name`，将基于 `dataset/model_name/timestamp` 生成，但在四阶段管线中由上游明确设置。
  - 实例化 `Trainer_KBQA` 并调用 `train(0, num_epoch-1)` 或 `evaluate_single`（评估模式）。

四、主训练循环与反向传播（gnn/train_model.py::Trainer_KBQA）
- 优化器与调度：
  - `optim.Adam(trainable_params, lr=self.learning_rate)`。
  - 若 `decay_rate > 0` 则启用 `ExponentialLR`；解析默认为 0.0，因此除非用户配置覆盖，否则不会启用调度。
- 训练主流程（按 epoch 循环）：
  - 每轮内调用 `train_epoch()`：
    - `self.train_data.reset_batches(is_sequential=False)`；迭代 `num_epoch = ceil(num_train / batch_size)` 次。
    - 对每个 batch：
      - 前向：`loss, _, _, (h1_list, f1_list) = self.model(batch, training=True)`。
      - 反向：`loss.backward()`。
      - 梯度裁剪：`clip_grad_norm_(model_params, gradient_clip)`。
      - 更新：`optim.step()`。
      - 记录训练期的 `h1/f1`。
  - 评估触发：当 `(epoch+1) % eval_every == 0` 时，先在验证集评估，超过 `warmup_epoch` 后根据 H1/F1 更新并保存 `-h1.ckpt`/`-f1.ckpt`；随后在测试集评估一次（并可写 `.info`）。
  - 结束：保存 `-final.ckpt`，若没有 H1/F1 别名则用 `final` 制作 `_best.pt` 别名；生成性能优化报告；调用 `evaluate_best()` 输出 H1/F1/Final 三套评估。

五、模型损失与评估细节（gnn/models/base_model.py, ReaRev）
- 基础损失（`BaseModel`）：
  - `loss_type=bce`：`BCEWithLogitsLoss`，标签平滑 0.9。
  - `loss_type=kl`：`KLDivLoss`，`log(pred)` 对 `answer_prob`（答案分布按和归一化）。
  - `get_loss(..., reduction='none'|'mean')`：支持按批平均（`kl` 用 `sum(...) / batch_size`）。
- ReaRev 前向：
  - 数据准备与指令生成后，执行 GNN 推理，累计 `dist_history`。
  - QA 基础损失：`calc_loss_label(pred_dist, answer_dist, label_valid)`；`label_valid = (有答案样本)` 屏蔽无答案样本。
  - PCST 增强损失（训练态启用且配置 `use_pcst`）：`total_loss = qa_loss + (sum(pcst_lambda)) * pcst_soft_regularizer(...)`，并做异常回退为 0 损失。
  - 评估：`get_eval_metric(pred_dist, answer_dist)` 产出 `h1` 与按阈值累积概率的 `f1`。

六、数据批与前向输入（gnn/dataset_load.py）
- `SingleDataLoader.get_batch()` 返回：
  - `local_entity`、`query_entities`、`kb_adj_mat`、`query_text`、`seed_dist`、`true_batch_id`、`answer_dist`。
- 前向中将以上转为张量并构建掩码与指令；ReaRev/NSM/GraftNet 均以 `pred_dist` 为实体概率分布进行监督。

七、断点与结果文件
- 断点：
  - 训练过程保存 `exp-<reason>.ckpt`（`reason` ∈ {`h1`,`f1`,`final`}），并维护阶段别名 `exp_best.pt` 供下一阶段承接。
  - 四阶段管线解析上一阶段断点名的简写或带前缀名，并自动退化为 `-f1.ckpt`、`-h1.ckpt`、`-final.ckpt`。
- 结果：
  - 最终评估后在 `gnn/outputs/gnn_rag3_<dataset>/<experiment>_test.info` 生成样本级指标。
  - 汇总写入 `final_results.json`（平均 `f1`、`precision`、`recall`、`hit_10`、`em`）。

八、关键超参数及默认值
- 训练：`num_epoch=100`、`eval_every=2`、`batch_size=20`、`lr=5e-4`、`gradient_clip=1.0`、`warmup_epoch=0`、`seed=19960626`、`fact_drop=0`。
- 结构：`entity_dim=50`、`kg_dim=100`、`word_dim=300`、`lm_dropout=0.3`、`linear_dropout=0.2`。
- ReaRev：`num_iter=2`、`num_ins=3`、`num_gnn=3`、`loss_type=kl`、`norm_rel`（可选）、`pos_emb`（可选）。
- RAG³：`use_appr`/`appr_alpha=0.85`/`cand_n=1200`；`use_dde`/`hop_dim=16`/`dir_dim=8`；`use_pcst`/`pcst_lambda=0.1,0.1,0.05`；`mid_restart`。
- 优化：`use_optimization`、`enable_sync_optimization`、`enable_adaptive_subgraph`、`enable_memory_monitoring`、`min_candidates=300`、`max_candidates=2000`。
- 多卡：`use_multi_gpu`、`gpu_ids="0,1"`。

九、注意事项与实践建议
- `eval_every` 在四阶段脚本中按“步数”配置，但传入 `gnn.main` 会折算到“轮数”，例如 `1000` → `10`（便于节奏一致）。
- `decay_rate` 解析默认为 0.0，若需指数学习率调度请显式设置为 `>0`。
- 四阶段默认配置中的某些键（如 `freeze_gnn`、`train_hybrid_only`）仅作文档性标记，不会传入底层训练入口。
- 为避免 `gnn/main.py` 的 `experiment_name` 自动生成逻辑引用未定义的 `dataset` 字段，请始终由四阶段脚本明确设置 `--experiment_name`。

文件位置与运行入口
- 管线入口：`d:\GNN-RAG-main\train_gnn_rag.py`
- 训练入口：`python -m gnn.main ReaRev ...`
- 关键代码：`gnn/train_model.py`、`gnn/models/ReaRev/rearev.py`、`gnn/models/base_model.py`、`gnn/dataset_load.py`、`gnn/parsing.py`。